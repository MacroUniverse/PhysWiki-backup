% test22

\begin{enumerate}
\item sasa
	\item [(1)]
    攻击目标：对于预训练好的DNN模型，攻击者对其进行有目标攻击，通过对原本正确分类的样本施加语义保留的扰动变换来生成对抗样本．生成的对抗样本可以成功欺骗DNN模型，使其给出错误的输出，但同时不影响人眼对其的正确识别．

	\item [(2)]
    攻击知识：攻击者在黑盒场景下对目标模型进行攻击，无法获得目标模型相关的先验知识（如模型结构、模型权重和训练参数等信息）．攻击者只能通过查询模型在给定输入上的输出结果，利用“输入-输出”信息对来进行攻击．

	\item [(3)]
    攻击能力：攻击者在测试阶段通过修改输入数据来实现探索性（躲闪）攻击．攻击者可以通过像素级别变换（随机修改像素值、添加噪声等）和微小的仿射变换（旋转、平移、缩放等）来对输入数据进行变异扰动．同时，在扰动大小不改变原始样本核心语义的情况下，对具体扰动变换不做其他约束．

	\item [(4)]
    攻击策略：攻击者利用一个两阶段进化算法的攻击策略（基于变换向量的进化和基于扰动图像的进化）来寻找高鲁棒性和高欺骗性的对抗样本，对目标模型进行攻击．与基于模糊测试的数据增强策略类似，攻击者通过选择保守的变换参数来确保最终的扰动不会影响原始图像中的核心语义信息．

\end{enumerate}